{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "import datetime\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import shutil \n",
    "import math\n",
    "import numpy as np\n",
    "from albumentations.augmentations import transforms\n",
    "import skimage\n",
    "from tqdm import tqdm\n",
    "\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats as s\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten, Activation, GRU\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, Convolution2D, ZeroPadding2D, Bidirectional, TimeDistributed\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image, sequence\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import optimizers\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "#os.makedirs(base_dir)\n",
    "os.makedirs(train_dir)\n",
    "os.makedirs(val_dir)\n",
    "os.makedirs(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Begin', 'Choose', 'Connection', 'Navigation', 'Next', 'Previous']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = 'Begin, Choose, Connection, Navigation, Next, Previous, Start, Stop, Hello, Web'\n",
    "classes = classes.split(', ')\n",
    "classes = classes[:6]\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in classes:\n",
    "    train_vids_dir = os.path.join(train_dir, class_name)\n",
    "    val_vids_dir = os.path.join(val_dir, class_name)\n",
    "    test_vids_dir = os.path.join(test_dir, class_name)\n",
    "    \n",
    "    os.makedirs(train_vids_dir)\n",
    "    os.makedirs(val_vids_dir)\n",
    "    os.makedirs(test_vids_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F01', 'F02', 'F04', 'F05', 'F06', 'F07', 'F08', 'F09', 'M01', 'M04']\n",
      "['F10', 'M07']\n",
      "['F11', 'M08']\n",
      "['01', '02', '03', '04', '05', '06']\n",
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']\n"
     ]
    }
   ],
   "source": [
    "train_people = 'F01, F02, F04, F05, F06, F07, F08, F09, M01, M04'.split(', ')\n",
    "#train_people = 'F01, F02, F05, F06, F07, F09, M01, M04'.split(', ')\n",
    "val_people = 'F10, M07'.split(', ')\n",
    "test_people = 'F11, M08'.split(', ')\n",
    "print(train_people)\n",
    "print(val_people)\n",
    "print(test_people)\n",
    "\n",
    "classes_num = ['0'+str(i) if i < 10 else str(i) for i in range(1, 11) ]\n",
    "classes_num = classes_num[:6]\n",
    "print(classes_num)\n",
    "word_ids = ['0'+str(i) if i < 10 else str(i) for i in range(1, 11) ]\n",
    "print(word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Begin'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_dict = dict(zip(classes_num, classes))\n",
    "classes_dict['01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img, figsize=(8, 8)):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.grid(False)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.imshow(img)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:16<00:00,  7.65s/it]\n",
      "100%|██████████| 10/10 [01:14<00:00,  7.46s/it]\n",
      "100%|██████████| 10/10 [00:58<00:00,  5.82s/it]\n",
      "100%|██████████| 10/10 [01:03<00:00,  6.31s/it]\n",
      "100%|██████████| 10/10 [00:46<00:00,  4.63s/it]\n",
      "100%|██████████| 10/10 [00:57<00:00,  5.72s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'07'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-dd0787a9fb33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m                             \u001b[0;34m+\u001b[0m \u001b[0mperson\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                             \u001b[0;34m+\u001b[0m \u001b[0mword_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                             + f[28:-4] + '.jpg', img)\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: '07'"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for classi in classes_num:\n",
    "    for person in tqdm(train_people):\n",
    "        for word_id in word_ids:\n",
    "            for f in sorted(glob.glob(os.path.join('data/miracl/'+person+'/words/'+classi+'/'+ word_id, \"*.jpg\"))):\n",
    "                img = cv2.imread(f, 1)\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                rects = detector(gray, 0)\n",
    "                \n",
    "                for k, rect in enumerate(rects):\n",
    "                    x1 = rect.left()\n",
    "                    y1 = rect.top()\n",
    "                    x2 = rect.right()\n",
    "                    y2 = rect.bottom()\n",
    "                    \n",
    "                    offset_x = (100-(abs(x1-x2)))/2\n",
    "                    offset_y = (100-(abs(y1-y2)))/2\n",
    "                    \n",
    "                    img = img[int(y1-offset_y):int(y2+offset_y), int(x1-offset_x):int(x2+offset_x)]\n",
    "                \n",
    "                counter += 1\n",
    "                \n",
    "                #cv2.imwrite('data/train/' + classes_dict[classi] + '/' + classi + '_' \n",
    "                #            + person + '_' \n",
    "                #            + word_id + '_' \n",
    "                #            + 'frame' + f[29:-4] + '.jpg', img)\n",
    "                cv2.imwrite('data/train/' \n",
    "                            + classes_dict[classi] + '/' \n",
    "                            + classi  + '_' \n",
    "                            + person  + '_' \n",
    "                            + word_id + '_' \n",
    "                            + f[28:-4] + '.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx(classi):\n",
    "    start_idx = (len('data/train/') + len(classi)+1)\n",
    "    return start_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(get_idx('Web'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin dir: removed 0 files. 1090 to be augmented\n",
      "Horizontally flipped 1090 files. 2180 in the directory\n",
      "Vertically flipped 1090 files. 3270 in the directory\n",
      "Noised 3270 files. 6540 in the directory\n",
      "\n",
      "Choose dir: removed 0 files. 1045 to be augmented\n",
      "Horizontally flipped 1045 files. 2090 in the directory\n",
      "Vertically flipped 1045 files. 3135 in the directory\n",
      "Noised 3135 files. 6270 in the directory\n",
      "\n",
      "Connection dir: removed 0 files. 1150 to be augmented\n",
      "Horizontally flipped 1150 files. 2300 in the directory\n",
      "Vertically flipped 1150 files. 3450 in the directory\n",
      "Noised 3450 files. 6900 in the directory\n",
      "\n",
      "Navigation dir: removed 0 files. 1281 to be augmented\n",
      "Horizontally flipped 1281 files. 2562 in the directory\n",
      "Vertically flipped 1281 files. 3843 in the directory\n",
      "Noised 3843 files. 7686 in the directory\n",
      "\n",
      "Next dir: removed 0 files. 950 to be augmented\n",
      "Horizontally flipped 950 files. 1900 in the directory\n",
      "Vertically flipped 950 files. 2850 in the directory\n",
      "Noised 2850 files. 5700 in the directory\n",
      "\n",
      "Previous dir: removed 0 files. 1149 to be augmented\n",
      "Horizontally flipped 1149 files. 2298 in the directory\n",
      "Vertically flipped 1149 files. 3447 in the directory\n",
      "Noised 3447 files. 6894 in the directory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for classi in classes:\n",
    "    files = [file for file in sorted(glob.glob(os.path.join('data/train/' + classi + '/*.jpg')))]\n",
    "    files_clean = [file_clean for file_clean in sorted(files)\n",
    "                   if 'vert_flip' not in file_clean\n",
    "                   and 'hor_flip' not in file_clean\n",
    "                   and 'rot_45' not in file_clean\n",
    "                   and 'rot_315' not in file_clean\n",
    "                   and 'rot_135' not in file_clean\n",
    "                   and 'rot_225' not in file_clean\n",
    "                   and 'rot_90' not in file_clean\n",
    "                   and 'rot_270' not in file_clean\n",
    "                   and 'rand_contr' not in file_clean\n",
    "                   and 'noised' not in file_clean]\n",
    "    files_rem = [file_rem for file_rem in sorted(files)\n",
    "                   if 'vert_flip' in file_rem\n",
    "                   or 'hor_flip' in file_rem\n",
    "                   or 'rot_45' in file_rem\n",
    "                   or 'rot_315' in file_rem\n",
    "                   or 'rot_135' in file_rem\n",
    "                   or 'rot_225' in file_rem\n",
    "                   or 'rot_90' in file_rem\n",
    "                   or 'rot_270' in file_rem\n",
    "                   or 'rand_contr' in file_rem\n",
    "                   or 'noised' in file_rem]\n",
    "    for file_to_rem in files_rem: os.remove(file_to_rem)\n",
    "    files = [file for file in sorted(glob.glob(os.path.join('data/train/' + classi + '/*.jpg')))]\n",
    "    print(classi, 'dir: removed', len(files_rem), 'files.', len(files), 'to be augmented')\n",
    "\n",
    "    for file_to_hor_flip in files_clean:\n",
    "        img = cv2.imread(file_to_hor_flip, 1)\n",
    "        img = transforms.HorizontalFlip().apply(img)\n",
    "        file_to_write = file_to_hor_flip[:get_idx(classi)] + '[hor_flip]' + file_to_hor_flip[get_idx(classi):]\n",
    "        cv2.imwrite(file_to_write, img)\n",
    "    files = [file for file in sorted(glob.glob(os.path.join('data/train/' + classi + '/*.jpg')))]\n",
    "    files_hor_flipped = [file_hor_flipped for file_hor_flipped in sorted(files) if 'hor_flip' in file_hor_flipped]\n",
    "    print('Horizontally flipped', len(files_hor_flipped), 'files.', len(files), 'in the directory')\n",
    "    \n",
    "    for file_to_vert_flip in files_clean:\n",
    "        img = cv2.imread(file_to_vert_flip, 1)\n",
    "        img = transforms.VerticalFlip().apply(img)\n",
    "        file_to_write = file_to_vert_flip[:get_idx(classi)] + '[vert_flip]' + file_to_vert_flip[get_idx(classi):]\n",
    "        cv2.imwrite(file_to_write, img)\n",
    "    files = [file for file in sorted(glob.glob(os.path.join('data/train/' + classi + '/*.jpg')))]\n",
    "    files_vert_flipped = [file_vert_flipped for file_vert_flipped in sorted(files) if 'vert_flip' in file_vert_flipped]\n",
    "    print('Vertically flipped', len(files_vert_flipped), 'files.', len(files), 'in the directory')\n",
    "    \n",
    "    #files_not_noised = [f for f in sorted(glob.glob(os.path.join('data/train/' + classi + '/*.jpg'))) if 'noised' not in f ]    \n",
    "    #for file_to_rand_contr in files_not_noised:\n",
    "    #    img = cv2.imread(file_to_rand_contr, 1)\n",
    "    #    img = transforms.RandomContrast().apply(img)\n",
    "    #    file_to_write = file_to_rand_contr[:get_idx(classi)] + '[rand_contr]' + file_to_rand_contr[get_idx(classi):]\n",
    "    #    #print(file_to_rand_contr)\n",
    "    #    #print(file_to_write)\n",
    "    #    cv2.imwrite(file_to_write, img)\n",
    "    #files = [file for file in sorted(glob.glob(os.path.join('data/train/' + classi + '/*.jpg')))]\n",
    "    #files_rand_contred = [file_rand_contred for file_rand_contred in sorted(files) if 'rand_contr' in file_rand_contred]\n",
    "    #print('Random contrasted', len(files_rand_contred), 'files.', len(files), 'in the directory')\n",
    "    \n",
    "    files_not_rand_contred = [file_not_rand_contred for file_not_rand_contred in sorted(files) if 'rand_contr' not in file_not_rand_contred]\n",
    "    for file_to_noise in files_not_rand_contred:\n",
    "        if '[hor_flip]' in file_to_noise:\n",
    "            img = cv2.imread(file_to_noise, 1)\n",
    "            gauss = np.random.uniform(0, 64, img.size)\n",
    "            gauss = gauss.reshape(img.shape[0],img.shape[1],img.shape[2]).astype('uint8')\n",
    "            img = cv2.add(img,gauss)\n",
    "            file_to_write = file_to_noise[:get_idx(classi)] + '[noised]' + file_to_noise[get_idx(classi):]\n",
    "            #print(file_to_noise)\n",
    "            #print(file_to_write)\n",
    "            cv2.imwrite(file_to_write, img)\n",
    "        elif '[vert_flip]' in file_to_noise:\n",
    "            img = cv2.imread(file_to_noise, 1)\n",
    "            gauss = np.random.uniform(0, 64, img.size)\n",
    "            gauss = gauss.reshape(img.shape[0],img.shape[1],img.shape[2]).astype('uint8')\n",
    "            img = cv2.add(img,gauss)\n",
    "            file_to_write = file_to_noise[:get_idx(classi)] + '[noised]' + file_to_noise[get_idx(classi):]\n",
    "            cv2.imwrite(file_to_write, img)\n",
    "        else:\n",
    "            img = cv2.imread(file_to_noise, 1)\n",
    "            gauss = np.random.uniform(0, 64, img.size)\n",
    "            gauss = gauss.reshape(img.shape[0],img.shape[1],img.shape[2]).astype('uint8')\n",
    "            img = cv2.add(img,gauss)\n",
    "            file_to_write = file_to_noise[:get_idx(classi)] + '[noised]' + file_to_noise[get_idx(classi):]\n",
    "            cv2.imwrite(file_to_write, img)\n",
    "    files = [file for file in sorted(glob.glob(os.path.join('data/train/' + classi + '/*.jpg')))]\n",
    "    files_noised = [file_noised for file_noised in sorted(files) if 'noised' in file_noised]\n",
    "    print('Noised', len(files_noised), 'files.', len(files), 'in the directory')\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:06<00:00,  3.34s/it]\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.06s/it]\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.82s/it]\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.84s/it]\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.47s/it]\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.05s/it]\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for classi in classes_num:\n",
    "    for person in tqdm(val_people):\n",
    "        for word_id in word_ids:\n",
    "            for f in sorted(glob.glob(os.path.join('data/miracl/'+person+'/words/'+classi+'/'+ word_id, \"*.jpg\"))):\n",
    "            #for f in sorted(glob.glob(os.path.join('MIRACL/'+person+'/words/'+classi+'/'+ word_id, \"*.jpg\"))):\n",
    "                img = cv2.imread(f, 1)\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                rects = detector(gray, 0)\n",
    "                \n",
    "                for k, rect in enumerate(rects):\n",
    "                    x1 = rect.left()\n",
    "                    y1 = rect.top()\n",
    "                    x2 = rect.right()\n",
    "                    y2 = rect.bottom()\n",
    "                    \n",
    "                    offset_x = (100-(abs(x1-x2)))/2\n",
    "                    offset_y = (100-(abs(y1-y2)))/2\n",
    "                    \n",
    "                    img = img[int(y1-offset_y):int(y2+offset_y), int(x1-offset_x):int(x2+offset_x)]\n",
    "                \n",
    "                counter += 1\n",
    "                \n",
    "                #cv2.imwrite('data/validation/' \n",
    "                #            + classes_dict[classi] + '/' \n",
    "                #            + classi + '_' \n",
    "                #            + person + '_' \n",
    "                #            + word_id + '_' \n",
    "                #            + 'frame' + f[29:-4] + '.jpg', img)\n",
    "                \n",
    "                cv2.imwrite('data/validation/' \n",
    "                            + classes_dict[classi] + '/' \n",
    "                            + classi  + '_' \n",
    "                            + person  + '_' \n",
    "                            + word_id + '_' \n",
    "                            + f[28:-4] + '.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 25.82it/s]\n"
     ]
    }
   ],
   "source": [
    "train_image = []\n",
    "train_class = []\n",
    "\n",
    "for class_id in tqdm(range(len(classes))):\n",
    "    images = sorted(glob.glob('data/train/' + classes[class_id] + '/*.jpg'))\n",
    "    for i in range(len(images)):\n",
    "        if ('noised' in images[i] or 'rand_contr' in images[i]\n",
    "        or 'vert_flip' in images[i] or 'hor_flip' in images[i]):\n",
    "            train_image.append(images[i].split('/')[3])\n",
    "            #print(images[i].split('/')[3])\n",
    "            train_class.append(classes_dict[images[i].split('/')[3].split(']')[-1][:2]])\n",
    "            #print(images[i].split('/')[3].split(']')[-1][:2])\n",
    "        else:\n",
    "            #print(images[i])\n",
    "            train_image.append(images[i].split('/')[3])\n",
    "            #print(images[i].split('/')[3])\n",
    "            train_class.append(classes_dict[images[i].split('/')[3].split('_')[0]])\n",
    "            #print(images[i].split('/')[3].split('_')[0])\n",
    "        \n",
    "train_data = pd.DataFrame()\n",
    "train_data['image'] = train_image\n",
    "train_data['class'] = train_class\n",
    "\n",
    "train_data.to_csv('data/miracl/train_new.csv',header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01_F01_01_color_001.jpg</td>\n",
       "      <td>Begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_F01_01_color_002.jpg</td>\n",
       "      <td>Begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01_F01_01_color_003.jpg</td>\n",
       "      <td>Begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01_F01_01_color_004.jpg</td>\n",
       "      <td>Begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01_F01_01_color_005.jpg</td>\n",
       "      <td>Begin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     image  class\n",
       "0  01_F01_01_color_001.jpg  Begin\n",
       "1  01_F01_01_color_002.jpg  Begin\n",
       "2  01_F01_01_color_003.jpg  Begin\n",
       "3  01_F01_01_color_004.jpg  Begin\n",
       "4  01_F01_01_color_005.jpg  Begin"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/miracl/train_new.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39985</th>\n",
       "      <td>[vert_flip]06_M04_10_color_006.jpg</td>\n",
       "      <td>Previous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39986</th>\n",
       "      <td>[vert_flip]06_M04_10_color_007.jpg</td>\n",
       "      <td>Previous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39987</th>\n",
       "      <td>[vert_flip]06_M04_10_color_008.jpg</td>\n",
       "      <td>Previous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39988</th>\n",
       "      <td>[vert_flip]06_M04_10_color_009.jpg</td>\n",
       "      <td>Previous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39989</th>\n",
       "      <td>[vert_flip]06_M04_10_color_010.jpg</td>\n",
       "      <td>Previous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    image     class\n",
       "39985  [vert_flip]06_M04_10_color_006.jpg  Previous\n",
       "39986  [vert_flip]06_M04_10_color_007.jpg  Previous\n",
       "39987  [vert_flip]06_M04_10_color_008.jpg  Previous\n",
       "39988  [vert_flip]06_M04_10_color_009.jpg  Previous\n",
       "39989  [vert_flip]06_M04_10_color_010.jpg  Previous"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39990"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = train['class']\n",
    "y_tr_dummy = pd.get_dummies(y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 730.82it/s]\n"
     ]
    }
   ],
   "source": [
    "val_image = []\n",
    "val_class = []\n",
    "\n",
    "for class_id in tqdm(range(len(classes))):\n",
    "    images = sorted(glob.glob('data/validation/' + classes[class_id] + '/*.jpg'))\n",
    "    for i in range(len(images)):\n",
    "        val_image.append(images[i].split('/')[3])\n",
    "        val_class.append(classes_dict[images[i].split('/')[3].split('_')[0]])\n",
    "val_data = pd.DataFrame()\n",
    "val_data['image'] = val_image\n",
    "val_data['class'] = val_class\n",
    "\n",
    "val_data.to_csv('data/miracl/val_new.csv',header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01_F10_01_color_001.jpg</td>\n",
       "      <td>Begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_F10_01_color_002.jpg</td>\n",
       "      <td>Begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01_F10_01_color_003.jpg</td>\n",
       "      <td>Begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01_F10_01_color_004.jpg</td>\n",
       "      <td>Begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01_F10_01_color_005.jpg</td>\n",
       "      <td>Begin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     image  class\n",
       "0  01_F10_01_color_001.jpg  Begin\n",
       "1  01_F10_01_color_002.jpg  Begin\n",
       "2  01_F10_01_color_003.jpg  Begin\n",
       "3  01_F10_01_color_004.jpg  Begin\n",
       "4  01_F10_01_color_005.jpg  Begin"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = pd.read_csv('data/miracl/val_new.csv')\n",
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>06_M07_10_color_005.jpg</td>\n",
       "      <td>Previous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>06_M07_10_color_006.jpg</td>\n",
       "      <td>Previous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>06_M07_10_color_007.jpg</td>\n",
       "      <td>Previous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>06_M07_10_color_008.jpg</td>\n",
       "      <td>Previous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>06_M07_10_color_009.jpg</td>\n",
       "      <td>Previous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        image     class\n",
       "1097  06_M07_10_color_005.jpg  Previous\n",
       "1098  06_M07_10_color_006.jpg  Previous\n",
       "1099  06_M07_10_color_007.jpg  Previous\n",
       "1100  06_M07_10_color_008.jpg  Previous\n",
       "1101  06_M07_10_color_009.jpg  Previous"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1102"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = val['class']\n",
    "y_val_dummy = pd.get_dummies(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39990\n",
      "1102\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = MobileNet(weights='imagenet', include_top=False, input_shape=(100,100,3), pooling='avg')\n",
    "#conv_base = MobileNet(weights='imagenet', include_top=False, input_shape=(100,100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 101, 101, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 50, 50, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 50, 50, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 50, 50, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 50, 50, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 50, 50, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 50, 50, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 51, 51, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 25, 25, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 25, 25, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 25, 25, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 25, 25, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 25, 25, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 25, 25, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 25, 25, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 25, 25, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 12, 12, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 12, 12, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 12, 12, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 12, 12, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 6, 6, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 6, 6, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 6, 6, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 6, 6, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 6, 6, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 6, 6, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 6, 6, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 6, 6, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 6, 6, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 6, 6, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 6, 6, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 6, 6, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 3, 3, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 3, 3, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 3, 3, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 3, 3, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 3, 3, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 3, 3, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 3, 3, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "=================================================================\n",
      "Total params: 3,228,864\n",
      "Trainable params: 3,206,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 64\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 1024)) #like in global_average_pooling2d_1\n",
    "    labels = np.zeros(shape=(sample_count, 6)) # 10 - num of classes\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(100, 100),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        sys.stdout.write('\\rProcessed: %d, size of features: %f' %((i * batch_size), sys.getsizeof(features)*1e-6))\n",
    "        sys.stdout.flush()\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39990 images belonging to 6 classes.\n",
      "Processed: 40000, size of features: 327.598192"
     ]
    }
   ],
   "source": [
    "#TODO tqdm(range(len(....))\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1102 images belonging to 6 classes.\n",
      "Processed: 1152, size of features: 9.027696"
     ]
    }
   ],
   "source": [
    "validation_features, validation_labels = extract_features(val_dir, len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39990, 1024)\n",
      "(1102, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(validation_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327.598192\n",
      "9.027695999999999\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(train_features)*1e-6)\n",
    "print(sys.getsizeof(validation_features)*1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten them to (samples, 16384):\n",
    "# train_features = np.reshape(train_features, (41742, 3 * 3 * 1024))\n",
    "# validation_features = np.reshape(validation_features, (1746, 3 * 3 * 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39990, 1024)\n",
      "(1102, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(validation_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_rnn = np.reshape(train_features, (train_features.shape[0], 1, train_features.shape[1]))\n",
    "\n",
    "\n",
    "validation_features_rnn = np.reshape(validation_features, (validation_features.shape[0], 1, validation_features.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39990, 1, 1024)\n",
      "(1102, 1, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(train_features_rnn.shape)\n",
    "print(validation_features_rnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(1, 1024)))\n",
    "model.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "#model.add(LSTM(256, input_shape=(1, 9216)))\n",
    "#model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fc = Sequential()\n",
    "model_fc.add(Dense(128, activation='relu', input_dim=1024))\n",
    "model_fc.add(Dropout(0.3))\n",
    "model_fc.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 132,490\n",
      "Trainable params: 132,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "adam2 = optimizers.Adam(lr=0.00001)\n",
    "save_weights = ModelCheckpoint('weight_fc.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "model_fc.compile(loss='categorical_crossentropy',optimizer=adam2,metrics=['accuracy'])\n",
    "model_fc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 256)               1311744   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,313,286\n",
      "Trainable params: 1,313,286\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "adam2 = optimizers.Adam(lr=0.00001)\n",
    "save_weights = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "model.compile(loss='categorical_crossentropy',optimizer=adam2,metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39990 samples, validate on 1102 samples\n",
      "Epoch 1/20\n",
      "39990/39990 [==============================] - 17s 423us/step - loss: 0.6967 - acc: 0.8184 - val_loss: 2.7502 - val_acc: 0.1488\n",
      "Epoch 2/20\n",
      "39990/39990 [==============================] - 17s 428us/step - loss: 0.6856 - acc: 0.8215 - val_loss: 2.7687 - val_acc: 0.1479\n",
      "Epoch 3/20\n",
      "39990/39990 [==============================] - 16s 409us/step - loss: 0.6749 - acc: 0.8240 - val_loss: 2.8022 - val_acc: 0.1497\n",
      "Epoch 4/20\n",
      "39990/39990 [==============================] - 17s 427us/step - loss: 0.6643 - acc: 0.8271 - val_loss: 2.8199 - val_acc: 0.1497\n",
      "Epoch 5/20\n",
      "39990/39990 [==============================] - 17s 425us/step - loss: 0.6542 - acc: 0.8293 - val_loss: 2.8264 - val_acc: 0.1506\n",
      "Epoch 6/20\n",
      "39990/39990 [==============================] - 17s 427us/step - loss: 0.6442 - acc: 0.8319 - val_loss: 2.8486 - val_acc: 0.1470\n",
      "Epoch 7/20\n",
      "39990/39990 [==============================] - 18s 438us/step - loss: 0.6346 - acc: 0.8351 - val_loss: 2.8337 - val_acc: 0.1506\n",
      "Epoch 8/20\n",
      "39990/39990 [==============================] - 17s 431us/step - loss: 0.6254 - acc: 0.8376 - val_loss: 2.8489 - val_acc: 0.1515\n",
      "Epoch 9/20\n",
      "39990/39990 [==============================] - 17s 431us/step - loss: 0.6163 - acc: 0.8398 - val_loss: 2.8929 - val_acc: 0.1515\n",
      "Epoch 10/20\n",
      "39990/39990 [==============================] - 18s 450us/step - loss: 0.6073 - acc: 0.8424 - val_loss: 2.8752 - val_acc: 0.1515\n",
      "Epoch 11/20\n",
      "39990/39990 [==============================] - 17s 432us/step - loss: 0.5986 - acc: 0.8442 - val_loss: 2.8859 - val_acc: 0.1506\n",
      "Epoch 12/20\n",
      "39990/39990 [==============================] - 17s 431us/step - loss: 0.5903 - acc: 0.8472 - val_loss: 2.9265 - val_acc: 0.1534\n",
      "Epoch 13/20\n",
      "39990/39990 [==============================] - 18s 444us/step - loss: 0.5821 - acc: 0.8493 - val_loss: 2.9308 - val_acc: 0.1543\n",
      "Epoch 14/20\n",
      "39990/39990 [==============================] - 17s 426us/step - loss: 0.5741 - acc: 0.8509 - val_loss: 2.9899 - val_acc: 0.1543\n",
      "Epoch 15/20\n",
      "39990/39990 [==============================] - 18s 449us/step - loss: 0.5662 - acc: 0.8532 - val_loss: 3.0122 - val_acc: 0.1534\n",
      "Epoch 16/20\n",
      "39990/39990 [==============================] - 18s 440us/step - loss: 0.5587 - acc: 0.8550 - val_loss: 3.0221 - val_acc: 0.1534\n",
      "Epoch 17/20\n",
      "39990/39990 [==============================] - 17s 435us/step - loss: 0.5512 - acc: 0.8577 - val_loss: 3.0332 - val_acc: 0.1534\n",
      "Epoch 18/20\n",
      "39990/39990 [==============================] - 17s 435us/step - loss: 0.5440 - acc: 0.8585 - val_loss: 3.0680 - val_acc: 0.1534\n",
      "Epoch 19/20\n",
      "39990/39990 [==============================] - 17s 427us/step - loss: 0.5370 - acc: 0.8606 - val_loss: 3.0470 - val_acc: 0.1561\n",
      "Epoch 20/20\n",
      "39990/39990 [==============================] - 17s 435us/step - loss: 0.5301 - acc: 0.8622 - val_loss: 3.0965 - val_acc: 0.1561\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_features_rnn, train_labels,\n",
    "                    epochs=20,\n",
    "                    batch_size=256,\n",
    "                    callbacks=[save_weights],\n",
    "                    validation_data=(validation_features_rnn, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_features_rnn, train_labels,\n",
    "                    epochs=8,\n",
    "                    batch_size=256,\n",
    "                    callbacks=[save_weights],\n",
    "                    validation_data=(validation_features_rnn, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weight.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=adam2,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1664.74it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1416.99it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2164.80it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2844.56it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2249.56it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2332.76it/s]\n"
     ]
    }
   ],
   "source": [
    "#files = glob.glob('data/test/*')\n",
    "#for file_rem in files:\n",
    "#    os.remove(file_rem)\n",
    "\n",
    "counter = 0\n",
    "for classi in classes_num:\n",
    "    for person in tqdm(test_people):\n",
    "        for word_id in word_ids:\n",
    "            for f in sorted(glob.glob(os.path.join('MIRACL/'+person+'/words/'+classi+'/'+ word_id, \"*.jpg\"))):\n",
    "                img = cv2.imread(f, 1)\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                rects = detector(gray, 0)\n",
    "                \n",
    "                for k, rect in enumerate(rects):\n",
    "                    x1 = rect.left()\n",
    "                    y1 = rect.top()\n",
    "                    x2 = rect.right()\n",
    "                    y2 = rect.bottom()\n",
    "                    \n",
    "                    offset_x = (100-(abs(x1-x2)))/2\n",
    "                    offset_y = (100-(abs(y1-y2)))/2\n",
    "                    \n",
    "                    img = img[int(y1-offset_y):int(y2+offset_y), int(x1-offset_x):int(x2+offset_x)]\n",
    "                \n",
    "                counter += 1\n",
    "                \n",
    "                cv2.imwrite('data/test/' + classes_dict[classi] + '/' + classi + '_' \n",
    "                            + person + '_' \n",
    "                            + word_id + '_' \n",
    "                            + 'frame' + f[29:-4] + '.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:07<00:00,  3.85s/it]\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.61s/it]\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.66s/it]\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.75s/it]\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.85s/it]\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.54s/it]\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('test_MIRACL/*')\n",
    "for file_rem in files:\n",
    "    os.remove(file_rem)\n",
    "\n",
    "counter = 0\n",
    "for classi in classes_num:\n",
    "    for person in tqdm(test_people):\n",
    "        for word_id in word_ids:\n",
    "            #for f in sorted(glob.glob(os.path.join('MIRACL/'+person+'/words/'+classi+'/'+ word_id, \"*.jpg\"))):\n",
    "            for f in sorted(glob.glob(os.path.join('data/miracl/'+person+'/words/'+classi+'/'+ word_id, \"*.jpg\"))):\n",
    "                img = cv2.imread(f, 1)\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                rects = detector(gray, 0)\n",
    "                \n",
    "                for k, rect in enumerate(rects):\n",
    "                    x1 = rect.left()\n",
    "                    y1 = rect.top()\n",
    "                    x2 = rect.right()\n",
    "                    y2 = rect.bottom()\n",
    "                    \n",
    "                    offset_x = (128-(abs(x1-x2)))/2\n",
    "                    offset_y = (128-(abs(y1-y2)))/2\n",
    "                    \n",
    "                    img = img[int(y1-offset_y):int(y2+offset_y), int(x1-offset_x):int(x2+offset_x)]\n",
    "                \n",
    "                counter += 1\n",
    "                \n",
    "                cv2.imwrite('data/test_miracl/' + classi + '_' \n",
    "                            + person + '_' \n",
    "                            + word_id + '_' \n",
    "                            + 'frame' + f[29:-4] + '.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 975/975 [00:00<00:00, 15417.39it/s]\n"
     ]
    }
   ],
   "source": [
    "images = sorted(glob.glob(\"data/test_miracl/*.jpg\"))\n",
    "test_image = []\n",
    "test_class = []\n",
    "for i in tqdm(range(len(images))):\n",
    "    #print(images[i])\n",
    "    test_image.append(sorted(images)[i].split('/')[2])\n",
    "    test_class.append(sorted(images)[i].split('/')[2][:2])\n",
    "\n",
    "\n",
    "test_data = pd.DataFrame()\n",
    "test_data['image'] = test_image\n",
    "test_data['class'] = test_class\n",
    "test_images = test_data['image']\n",
    "\n",
    "test_data.to_csv('test_new.csv',header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_new.csv')\n",
    "y_test = test['class']\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01_F11_01_frameolor_001.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_F11_01_frameolor_002.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01_F11_01_frameolor_003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01_F11_01_frameolor_004.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01_F11_01_frameolor_005.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         image  class\n",
       "0  01_F11_01_frameolor_001.jpg      1\n",
       "1  01_F11_01_frameolor_002.jpg      1\n",
       "2  01_F11_01_frameolor_003.jpg      1\n",
       "3  01_F11_01_frameolor_004.jpg      1\n",
       "4  01_F11_01_frameolor_005.jpg      1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>06_M08_10_frameolor_006.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>06_M08_10_frameolor_007.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>06_M08_10_frameolor_008.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>06_M08_10_frameolor_009.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>06_M08_10_frameolor_010.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image  class\n",
       "970  06_M08_10_frameolor_006.jpg      6\n",
       "971  06_M08_10_frameolor_007.jpg      6\n",
       "972  06_M08_10_frameolor_008.jpg      6\n",
       "973  06_M08_10_frameolor_009.jpg      6\n",
       "974  06_M08_10_frameolor_010.jpg      6"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    01_F11_01\n",
       "1    01_F11_02\n",
       "2    01_F11_03\n",
       "3    01_F11_04\n",
       "4    01_F11_05\n",
       "Name: dummy, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_names = sorted(list(set([test_images[i].split('.')[0][0:9] for i in range(len(test_images))])))\n",
    "test_videos = pd.DataFrame(video_names)\n",
    "\n",
    "test_videos.columns = ['dummy']\n",
    "test_videos = test_videos['dummy']\n",
    "\n",
    "print(test_videos.shape[0])\n",
    "test_videos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "970    06_M08_10_frameolor_006.jpg\n",
       "971    06_M08_10_frameolor_007.jpg\n",
       "972    06_M08_10_frameolor_008.jpg\n",
       "973    06_M08_10_frameolor_009.jpg\n",
       "974    06_M08_10_frameolor_010.jpg\n",
       "Name: image, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_images.shape[0])\n",
    "test_images.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:42<00:00,  2.84it/s]\n"
     ]
    }
   ],
   "source": [
    "predict = []\n",
    "actual = []\n",
    "\n",
    "for video_id in tqdm(range(test_videos.shape[0])):\n",
    "    videoFile = test_videos[video_id]\n",
    "    \n",
    "    files = glob.glob('temp/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    \n",
    "    for frame_id in range(test_images.shape[0]):\n",
    "        frame = test_images[frame_id]\n",
    "        if test_images[frame_id].split('.')[0][0:9] == videoFile:\n",
    "            img = shutil.copyfile('data/test_miracl/'+test_images[frame_id], 'temp/'+test_images[frame_id]) \n",
    "    \n",
    "    images = glob.glob(\"temp/*.jpg\")\n",
    "    \n",
    "    prediction_images = []\n",
    "    for i in range(len(images)):\n",
    "        img = image.load_img(images[i], target_size=(100,100,3))\n",
    "        img = image.img_to_array(img)\n",
    "        img = keras.applications.mobilenet.preprocess_input(img)\n",
    "        \n",
    "        prediction_images.append(img)\n",
    "        \n",
    "    prediction_images = np.array(prediction_images)\n",
    "    \n",
    "    prediction_images = conv_base.predict(prediction_images)\n",
    "    \n",
    "    #prediction_images = prediction_images.reshape(prediction_images.shape[0], 4 * 4 * 1024)\n",
    "    \n",
    "    prediction_images = np.reshape(prediction_images, \n",
    "                                   (prediction_images.shape[0], 1, prediction_images.shape[1])) #(x, 1, 1024)\n",
    "    \n",
    "    prediction = model.predict_classes(prediction_images)\n",
    "    predict.append(y_test.columns.values[s.mode(prediction)[0][0]])\n",
    "    \n",
    "    actual.append(int(videoFile.split('_')[0].lstrip('0')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.833333333333336"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predict, actual)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
