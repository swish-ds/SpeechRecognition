{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dlib\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['F01', 'F02', 'F04', 'F05', 'F06', 'F07', 'F08', 'F09', 'M01', 'M02', 'M04']\n['F10', 'M07']\n['F11', 'M08']\n['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']\n['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']\n{'01': 'Begin', '02': 'Choose', '03': 'Connection', '04': 'Navigation', '05': 'Next', '06': 'Previous', '07': 'Start', '08': 'Stop', '09': 'Hello', '10': 'Web'}\n"
    }
   ],
   "source": [
    "img_black = np.zeros((70,140,3))\n",
    "\n",
    "base_dir = 'data'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "classes = 'Begin, Choose, Connection, Navigation, Next, Previous, Start, Stop, Hello, Web'\n",
    "classes = classes.split(', ')\n",
    "\n",
    "predictor_path = 'assests/predictors/shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "train_people = 'F01, F02, F04, F05, F06, F07, F08, F09, M01, M02, M04'.split(', ')\n",
    "val_people = 'F10, M07'.split(', ')\n",
    "test_people = 'F11, M08'.split(', ')\n",
    "print(train_people)\n",
    "print(val_people)\n",
    "print(test_people)\n",
    "\n",
    "classes_num = ['0'+str(i) if i < 10 else str(i) for i in range(1, 11) ]\n",
    "word_ids = ['0'+str(i) if i < 10 else str(i) for i in range(1, 11) ]\n",
    "classes_dict = dict(zip(classes_num, classes))\n",
    "print(classes_num)\n",
    "print(word_ids)\n",
    "print(classes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img, figsize=(8, 8)):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.grid(False)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.imshow(img)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = []\n",
    "train_class = []\n",
    "\n",
    "for class_id in range(len(classes)):\n",
    "    images = sorted(glob.glob('data/train/' + classes[class_id] + '/*.jpg'))\n",
    "    for i in range(len(images)):\n",
    "        if ('noised' in images[i] or 'rand_contr' in images[i]\n",
    "        or 'vert_flip' in images[i] or 'hor_flip' in images[i]):\n",
    "            train_image.append(images[i].split('/')[3])\n",
    "            train_class.append(classes_dict[images[i].split('/')[3].split(']')[-1][:2]])\n",
    "        else:\n",
    "            train_image.append(images[i].split('/')[3])\n",
    "            train_class.append(classes_dict[images[i].split('/')[3].split('_')[0]])\n",
    "        \n",
    "train_data = pd.DataFrame()\n",
    "train_data['image'] = train_image\n",
    "train_data['class'] = train_class\n",
    "\n",
    "train_data.to_csv('data/miracl/train_new.csv',header=True, index=False)\n",
    "\n",
    "\n",
    "val_image = []\n",
    "val_class = []\n",
    "\n",
    "for class_id in range(len(classes)):\n",
    "    images = sorted(glob.glob('data/validation/' + classes[class_id] + '/*.jpg'))\n",
    "    for i in range(len(images)):\n",
    "        val_image.append(images[i].split('/')[3])\n",
    "        val_class.append(classes_dict[images[i].split('/')[3].split('_')[0]])\n",
    "val_data = pd.DataFrame()\n",
    "val_data['image'] = val_image\n",
    "val_data['class'] = val_class\n",
    "\n",
    "val_data.to_csv('data/miracl/val_new.csv',header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/miracl/train_new.csv')\n",
    "val = pd.read_csv('data/miracl/val_new.csv')\n",
    "\n",
    "y_tr = train['class']\n",
    "y_tr_dummy = pd.get_dummies(y_tr)\n",
    "\n",
    "y_val = val['class']\n",
    "y_val_dummy = pd.get_dummies(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01_F01_01_color_001.jpg</td>\n      <td>Begin</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01_F01_01_color_002.jpg</td>\n      <td>Begin</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01_F01_01_color_003.jpg</td>\n      <td>Begin</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01_F01_01_color_004.jpg</td>\n      <td>Begin</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01_F01_01_color_005.jpg</td>\n      <td>Begin</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                     image  class\n0  01_F01_01_color_001.jpg  Begin\n1  01_F01_01_color_002.jpg  Begin\n2  01_F01_01_color_003.jpg  Begin\n3  01_F01_01_color_004.jpg  Begin\n4  01_F01_01_color_005.jpg  Begin"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6915</th>\n      <td>10_M08_10_color_006.jpg</td>\n      <td>Web</td>\n    </tr>\n    <tr>\n      <th>6916</th>\n      <td>10_M08_10_color_007.jpg</td>\n      <td>Web</td>\n    </tr>\n    <tr>\n      <th>6917</th>\n      <td>10_M08_10_color_008.jpg</td>\n      <td>Web</td>\n    </tr>\n    <tr>\n      <th>6918</th>\n      <td>10_M08_10_color_009.jpg</td>\n      <td>Web</td>\n    </tr>\n    <tr>\n      <th>6919</th>\n      <td>10_M08_10_color_010.jpg</td>\n      <td>Web</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                        image class\n6915  10_M08_10_color_006.jpg   Web\n6916  10_M08_10_color_007.jpg   Web\n6917  10_M08_10_color_008.jpg   Web\n6918  10_M08_10_color_009.jpg   Web\n6919  10_M08_10_color_010.jpg   Web"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01_F10_01_color_001.jpg</td>\n      <td>Begin</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01_F10_01_color_002.jpg</td>\n      <td>Begin</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01_F10_01_color_003.jpg</td>\n      <td>Begin</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01_F10_01_color_004.jpg</td>\n      <td>Begin</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01_F10_01_color_005.jpg</td>\n      <td>Begin</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                     image  class\n0  01_F10_01_color_001.jpg  Begin\n1  01_F10_01_color_002.jpg  Begin\n2  01_F10_01_color_003.jpg  Begin\n3  01_F10_01_color_004.jpg  Begin\n4  01_F10_01_color_005.jpg  Begin"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1505</th>\n      <td>10_M07_10_color_006.jpg</td>\n      <td>Web</td>\n    </tr>\n    <tr>\n      <th>1506</th>\n      <td>10_M07_10_color_007.jpg</td>\n      <td>Web</td>\n    </tr>\n    <tr>\n      <th>1507</th>\n      <td>10_M07_10_color_008.jpg</td>\n      <td>Web</td>\n    </tr>\n    <tr>\n      <th>1508</th>\n      <td>10_M07_10_color_009.jpg</td>\n      <td>Web</td>\n    </tr>\n    <tr>\n      <th>1509</th>\n      <td>10_M07_10_color_010.jpg</td>\n      <td>Web</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                        image class\n1505  10_M07_10_color_006.jpg   Web\n1506  10_M07_10_color_007.jpg   Web\n1507  10_M07_10_color_008.jpg   Web\n1508  10_M07_10_color_009.jpg   Web\n1509  10_M07_10_color_010.jpg   Web"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "6920\n1510\n"
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2.1.0\n2.3.1\nUsing TensorFlow backend.\n"
    }
   ],
   "source": [
    "import keras\n",
    "#from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_datagen import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found 6920 images belonging to 10 classes.\nFound 1510 images belonging to 10 classes.\n"
    }
   ],
   "source": [
    "datagen = ImageDataGenerator()\n",
    "train_data = datagen.flow_from_directory('data/train', target_size=(70, 140), batch_size=1, frames_per_step=10, shuffle=False)\n",
    "val_data = datagen.flow_from_directory('data/validation', target_size=(70, 140), batch_size=1, frames_per_step=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "692\n151\n"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "print(math.ceil(6920/(1*10)))\n",
    "print(math.ceil((1510/(1*10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.regularizers import *\n",
    "from keras.constraints import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_small = keras.models.Sequential()\n",
    "\n",
    "model_small.add(ZeroPadding3D(padding=(1, 2, 2), input_shape=(10, 70, 140, 3)))\n",
    "model_small.add(Conv3D(32, (3, 5, 5), strides=(1, 2, 2), activation='relu'))\n",
    "model_small.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "model_small.add(Dropout(.2))\n",
    "\n",
    "model_small.add(ZeroPadding3D(padding=(1, 2, 2)))\n",
    "model_small.add(Conv3D(64, (3, 5, 5), strides=(1, 1, 1), activation='relu'))\n",
    "model_small.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "model_small.add(Dropout(.2))\n",
    "\n",
    "model_small.add(ZeroPadding3D(padding=(1, 1, 1)))\n",
    "model_small.add(Conv3D(96, (3, 3, 3), strides=(1, 2, 2), activation='relu'))\n",
    "model_small.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "model_small.add(Dropout(.2))\n",
    "\n",
    "model_small.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# model_small.add(Bidirectional(GRU(10, return_sequences=True)))\n",
    "model_small.add(Bidirectional(GRU(10)))\n",
    "\n",
    "model_small.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nzero_padding3d_1 (ZeroPaddin (None, 12, 74, 144, 3)    0         \n_________________________________________________________________\nconv3d_1 (Conv3D)            (None, 10, 35, 70, 32)    7232      \n_________________________________________________________________\nmax_pooling3d_1 (MaxPooling3 (None, 10, 17, 35, 32)    0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 10, 17, 35, 32)    0         \n_________________________________________________________________\nzero_padding3d_2 (ZeroPaddin (None, 12, 21, 39, 32)    0         \n_________________________________________________________________\nconv3d_2 (Conv3D)            (None, 10, 17, 35, 64)    153664    \n_________________________________________________________________\nmax_pooling3d_2 (MaxPooling3 (None, 10, 8, 17, 64)     0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 10, 8, 17, 64)     0         \n_________________________________________________________________\nzero_padding3d_3 (ZeroPaddin (None, 12, 10, 19, 64)    0         \n_________________________________________________________________\nconv3d_3 (Conv3D)            (None, 10, 4, 9, 96)      165984    \n_________________________________________________________________\nmax_pooling3d_3 (MaxPooling3 (None, 10, 2, 4, 96)      0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 10, 2, 4, 96)      0         \n_________________________________________________________________\ntime_distributed_1 (TimeDist (None, 10, 768)           0         \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 20)                46740     \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                210       \n=================================================================\nTotal params: 373,830\nTrainable params: 373,830\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "adam2 = keras.optimizers.Adam(lr=0.0001)\n",
    "save_weights = keras.callbacks.ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "model_small.compile(loss='categorical_crossentropy',optimizer=adam2,metrics=['accuracy'])\n",
    "model_small.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model_small.fit_generator(train_data, epochs=20, steps_per_epoch=231, \n",
    "#                               validation_data=val_data, validation_steps=51, \n",
    "#                               callbacks=[save_weights], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/20\n692/692 [==============================] - 55s 79ms/step - loss: 2.6256 - accuracy: 0.0896 - val_loss: 2.7680 - val_accuracy: 0.0596\nEpoch 2/20\n692/692 [==============================] - 49s 71ms/step - loss: 2.5071 - accuracy: 0.0997 - val_loss: 2.5843 - val_accuracy: 0.0464\nEpoch 3/20\n692/692 [==============================] - 47s 68ms/step - loss: 2.4258 - accuracy: 0.0939 - val_loss: 2.3817 - val_accuracy: 0.0464\nEpoch 4/20\n692/692 [==============================] - 44s 63ms/step - loss: 2.4016 - accuracy: 0.1503 - val_loss: 1.3630 - val_accuracy: 0.0861\nEpoch 5/20\n692/692 [==============================] - 45s 65ms/step - loss: 2.4351 - accuracy: 0.0838 - val_loss: 1.8117 - val_accuracy: 0.0464\nEpoch 6/20\n692/692 [==============================] - 44s 64ms/step - loss: 2.4044 - accuracy: 0.1156 - val_loss: 1.5778 - val_accuracy: 0.0728\nEpoch 7/20\n692/692 [==============================] - 44s 64ms/step - loss: 2.4317 - accuracy: 0.0882 - val_loss: 2.4108 - val_accuracy: 0.0464\nEpoch 8/20\n692/692 [==============================] - 44s 64ms/step - loss: 2.3829 - accuracy: 0.0780 - val_loss: 2.6081 - val_accuracy: 0.0464\nEpoch 9/20\n692/692 [==============================] - 44s 64ms/step - loss: 2.4132 - accuracy: 0.0824 - val_loss: 2.5911 - val_accuracy: 0.0464\nEpoch 10/20\n692/692 [==============================] - 44s 64ms/step - loss: 2.3625 - accuracy: 0.0882 - val_loss: 2.4832 - val_accuracy: 0.0464\nEpoch 11/20\n692/692 [==============================] - 44s 64ms/step - loss: 2.3372 - accuracy: 0.0809 - val_loss: 1.8810 - val_accuracy: 0.0464\nEpoch 12/20\n692/692 [==============================] - 44s 64ms/step - loss: 2.3553 - accuracy: 0.0853 - val_loss: 2.2370 - val_accuracy: 0.0662\nEpoch 13/20\n692/692 [==============================] - 45s 65ms/step - loss: 2.4128 - accuracy: 0.0650 - val_loss: 2.3500 - val_accuracy: 0.0662\nEpoch 14/20\n692/692 [==============================] - 45s 65ms/step - loss: 2.3919 - accuracy: 0.0809 - val_loss: 2.4431 - val_accuracy: 0.0397\nEpoch 15/20\n692/692 [==============================] - 45s 65ms/step - loss: 2.3899 - accuracy: 0.0679 - val_loss: 2.2685 - val_accuracy: 0.0662\nEpoch 16/20\n692/692 [==============================] - 45s 65ms/step - loss: 2.3533 - accuracy: 0.0809 - val_loss: 2.3175 - val_accuracy: 0.1060\nEpoch 17/20\n692/692 [==============================] - 45s 65ms/step - loss: 2.3671 - accuracy: 0.0780 - val_loss: 2.3301 - val_accuracy: 0.0927\nEpoch 18/20\n692/692 [==============================] - 45s 65ms/step - loss: 2.3684 - accuracy: 0.0679 - val_loss: 2.0367 - val_accuracy: 0.0662\nEpoch 19/20\n692/692 [==============================] - 45s 65ms/step - loss: 2.4043 - accuracy: 0.1113 - val_loss: 2.6360 - val_accuracy: 0.0993\nEpoch 20/20\n692/692 [==============================] - 45s 65ms/step - loss: 2.3854 - accuracy: 0.1055 - val_loss: 2.4351 - val_accuracy: 0.0662\n"
    }
   ],
   "source": [
    "history = model_small.fit_generator(train_data, steps_per_epoch=692, epochs=20, validation_data=val_data, validation_steps=151, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video = keras.layers.Input(shape=(10, 70, 140, 3))\n",
    "\n",
    "# cnn_base = keras.applications.MobileNetV2(input_shape=(70, 140, 3), include_top=False)\n",
    "# cnn_out = keras.layers.GlobalAveragePooling2D()(cnn_base.output)\n",
    "\n",
    "# cnn = Model(input=cnn_base.input, output=cnn_out)\n",
    "# encoded_frames = keras.layers.TimeDistributed(cnn)(video)\n",
    "\n",
    "# encoded_sequence = keras.layers.Bidirectional(LSTM(10))(encoded_frames)\n",
    "# outputs = keras.layers.Bidirectional(Dense(10, activation=\"softmax\"))(encoded_sequence)\n",
    "\n",
    "# mn_lstm = Model([video], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam2 = keras.optimizers.Adam(lr=0.0001)\n",
    "# save_weights = keras.callbacks.ModelCheckpoint('mn_lstm.hdf5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "# mn_lstm.compile(loss='categorical_crossentropy',optimizer=adam2,metrics=['accuracy'])\n",
    "# mn_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = mn_lstm.fit_generator(train_data, epochs=20, steps_per_epoch=692, \n",
    "#                               validation_data=val_data, validation_steps=151, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lr.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}