{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "import datetime\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import shutil \n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats as s\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten, Activation, GRU\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, Convolution2D, ZeroPadding2D, Bidirectional, TimeDistributed\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image, sequence\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import optimizers\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.makedirs(base_dir)\n",
    "os.makedirs(train_dir)\n",
    "os.makedirs(val_dir)\n",
    "os.makedirs(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Begin', 'Choose', 'Connection', 'Navigation']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = 'Begin, Choose, Connection, Navigation, Next, Previous, Start, Stop, Hello, Web'\n",
    "classes = classes.split(', ')\n",
    "classes[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in classes:\n",
    "    train_vids_dir = os.path.join(train_dir, class_name)\n",
    "    val_vids_dir = os.path.join(val_dir, class_name)\n",
    "    #test_vids_dir = os.path.join(test_dir, class_name)\n",
    "    \n",
    "    os.makedirs(train_vids_dir)\n",
    "    os.makedirs(val_vids_dir)\n",
    "    #os.makedirs(test_vids_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F01', 'F02', 'F04', 'F05', 'F06', 'F07', 'F08', 'F09', 'M01', 'M04']\n",
      "['F10', 'M07']\n",
      "['F11', 'M08']\n",
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']\n",
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']\n"
     ]
    }
   ],
   "source": [
    "train_people = 'F01, F02, F04, F05, F06, F07, F08, F09, M01, M04'.split(', ')\n",
    "val_people = 'F10, M07'.split(', ')\n",
    "test_people = 'F11, M08'.split(', ')\n",
    "print(train_people)\n",
    "print(val_people)\n",
    "print(test_people)\n",
    "\n",
    "classes_num = ['0'+str(i) if i < 10 else str(i) for i in range(1, 11) ]\n",
    "print(classes_num)\n",
    "word_ids = ['0'+str(i) if i < 10 else str(i) for i in range(1, 11) ]\n",
    "print(word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'01': 'Begin',\n",
       " '02': 'Choose',\n",
       " '03': 'Connection',\n",
       " '04': 'Navigation',\n",
       " '05': 'Next',\n",
       " '06': 'Previous',\n",
       " '07': 'Start',\n",
       " '08': 'Stop',\n",
       " '09': 'Hello',\n",
       " '10': 'Web'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_dict = dict(zip(classes_num, classes))\n",
    "classes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Begin'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_dict['01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:20<00:00,  8.02s/it]\n",
      "100%|██████████| 10/10 [01:17<00:00,  7.77s/it]\n",
      "100%|██████████| 10/10 [01:23<00:00,  8.38s/it]\n",
      "100%|██████████| 10/10 [01:33<00:00,  9.36s/it]\n",
      "100%|██████████| 10/10 [01:10<00:00,  7.06s/it]\n",
      "100%|██████████| 10/10 [01:23<00:00,  8.34s/it]\n",
      "100%|██████████| 10/10 [01:14<00:00,  7.49s/it]\n",
      "100%|██████████| 10/10 [01:18<00:00,  7.83s/it]\n",
      "100%|██████████| 10/10 [01:21<00:00,  8.15s/it]\n",
      "100%|██████████| 10/10 [01:11<00:00,  7.17s/it]\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for classi in classes_num:\n",
    "    for person in tqdm(train_people):\n",
    "        for word_id in word_ids:\n",
    "            for f in sorted(glob.glob(os.path.join('MIRACL/'+person+'/words/'+classi+'/'+ word_id, \"*.jpg\"))):\n",
    "                img = cv2.imread(f, 1)\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                rects = detector(gray, 0)\n",
    "                \n",
    "                for k, rect in enumerate(rects):\n",
    "                    x1 = rect.left()\n",
    "                    y1 = rect.top()\n",
    "                    x2 = rect.right()\n",
    "                    y2 = rect.bottom()\n",
    "                    \n",
    "                    offset_x = (128-(abs(x1-x2)))/2\n",
    "                    offset_y = (128-(abs(y1-y2)))/2\n",
    "                    \n",
    "                    img = img[int(y1-offset_y):int(y2+offset_y), int(x1-offset_x):int(x2+offset_x)]\n",
    "                \n",
    "                counter += 1\n",
    "                \n",
    "                cv2.imwrite('data/train/' + classes_dict[classi] + '/' + classi + '_' \n",
    "                            + person + '_' \n",
    "                            + word_id + '_' \n",
    "                            + 'frame' + f[29:-4] + '.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:11<00:00,  5.89s/it]\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.11s/it]\n",
      "100%|██████████| 2/2 [00:15<00:00,  7.57s/it]\n",
      "100%|██████████| 2/2 [00:15<00:00,  7.72s/it]\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.90s/it]\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.95s/it]\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.01s/it]\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.98s/it]\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.30s/it]\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.44s/it]\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for classi in classes_num:\n",
    "    for person in tqdm(val_people):\n",
    "        for word_id in word_ids:\n",
    "            for f in sorted(glob.glob(os.path.join('MIRACL/'+person+'/words/'+classi+'/'+ word_id, \"*.jpg\"))):\n",
    "                img = cv2.imread(f, 1)\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                rects = detector(gray, 0)\n",
    "                \n",
    "                for k, rect in enumerate(rects):\n",
    "                    x1 = rect.left()\n",
    "                    y1 = rect.top()\n",
    "                    x2 = rect.right()\n",
    "                    y2 = rect.bottom()\n",
    "                    \n",
    "                    offset_x = (128-(abs(x1-x2)))/2\n",
    "                    offset_y = (128-(abs(y1-y2)))/2\n",
    "                    \n",
    "                    img = img[int(y1-offset_y):int(y2+offset_y), int(x1-offset_x):int(x2+offset_x)]\n",
    "                \n",
    "                counter += 1\n",
    "                \n",
    "                cv2.imwrite('data/validation/' + classes_dict[classi] + '/' + classi + '_' \n",
    "                            + person + '_' \n",
    "                            + word_id + '_' \n",
    "                            + 'frame' + f[29:-4] + '.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 164.13it/s]\n"
     ]
    }
   ],
   "source": [
    "train_image = []\n",
    "train_class = []\n",
    "\n",
    "for class_id in tqdm(range(len(classes))):\n",
    "    images = sorted(glob.glob('data/train/' + classes[class_id] + '/*.jpg'))\n",
    "    for i in range(len(images)):\n",
    "        train_image.append(images[i].split('/')[3])\n",
    "        train_class.append(classes_dict[images[i].split('/')[3].split('_')[2]])\n",
    "        \n",
    "train_data = pd.DataFrame()\n",
    "train_data['image'] = train_image\n",
    "train_data['class'] = train_class\n",
    "\n",
    "train_data.to_csv('MIRACL/train_new.csv',header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01_F01_01_frame001.jpg</td>\n",
       "      <td>Begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_F01_01_frame002.jpg</td>\n",
       "      <td>Begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01_F01_01_frame003.jpg</td>\n",
       "      <td>Begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01_F01_01_frame004.jpg</td>\n",
       "      <td>Begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01_F01_01_frame005.jpg</td>\n",
       "      <td>Begin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    image  class\n",
       "0  01_F01_01_frame001.jpg  Begin\n",
       "1  01_F01_01_frame002.jpg  Begin\n",
       "2  01_F01_01_frame003.jpg  Begin\n",
       "3  01_F01_01_frame004.jpg  Begin\n",
       "4  01_F01_01_frame005.jpg  Begin"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('MIRACL/train_new.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10947</th>\n",
       "      <td>10_M04_10_frame007.jpg</td>\n",
       "      <td>Web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10948</th>\n",
       "      <td>10_M04_10_frame008.jpg</td>\n",
       "      <td>Web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10949</th>\n",
       "      <td>10_M04_10_frame009.jpg</td>\n",
       "      <td>Web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10950</th>\n",
       "      <td>10_M04_10_frame010.jpg</td>\n",
       "      <td>Web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10951</th>\n",
       "      <td>10_M04_10_frame011.jpg</td>\n",
       "      <td>Web</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        image class\n",
       "10947  10_M04_10_frame007.jpg   Web\n",
       "10948  10_M04_10_frame008.jpg   Web\n",
       "10949  10_M04_10_frame009.jpg   Web\n",
       "10950  10_M04_10_frame010.jpg   Web\n",
       "10951  10_M04_10_frame011.jpg   Web"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = train['class']\n",
    "y_tr_dummy = pd.get_dummies(y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 662.85it/s]\n"
     ]
    }
   ],
   "source": [
    "val_image = []\n",
    "val_class = []\n",
    "\n",
    "for class_id in tqdm(range(len(classes))):\n",
    "    images = glob.glob('data/validation/' + classes[class_id] + '/*.jpg')\n",
    "    for i in range(len(images)):\n",
    "        val_image.append(images[i].split('/')[3])\n",
    "        val_class.append(classes_dict[images[i].split('/')[3].split('_')[2]])\n",
    "        \n",
    "val_data = pd.DataFrame()\n",
    "val_data['image'] = val_image\n",
    "val_data['class'] = val_class\n",
    "\n",
    "val_data.to_csv('MIRACL/val_new.csv',header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01_M07_06_frame008.jpg</td>\n",
       "      <td>Previous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_M07_01_frame001.jpg</td>\n",
       "      <td>Begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01_F10_01_frame005.jpg</td>\n",
       "      <td>Begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01_F10_02_frame002.jpg</td>\n",
       "      <td>Choose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01_M07_08_frame004.jpg</td>\n",
       "      <td>Stop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    image     class\n",
       "0  01_M07_06_frame008.jpg  Previous\n",
       "1  01_M07_01_frame001.jpg     Begin\n",
       "2  01_F10_01_frame005.jpg     Begin\n",
       "3  01_F10_02_frame002.jpg    Choose\n",
       "4  01_M07_08_frame004.jpg      Stop"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = pd.read_csv('MIRACL/val_new.csv')\n",
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>10_M07_04_frame001.jpg</td>\n",
       "      <td>Navigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>10_M07_08_frame006.jpg</td>\n",
       "      <td>Stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>10_F10_02_frame001.jpg</td>\n",
       "      <td>Choose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>10_F10_08_frame006.jpg</td>\n",
       "      <td>Stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>10_M07_10_frame006.jpg</td>\n",
       "      <td>Web</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image       class\n",
       "1741  10_M07_04_frame001.jpg  Navigation\n",
       "1742  10_M07_08_frame006.jpg        Stop\n",
       "1743  10_F10_02_frame001.jpg      Choose\n",
       "1744  10_F10_08_frame006.jpg        Stop\n",
       "1745  10_M07_10_frame006.jpg         Web"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = val['class']\n",
    "y_val_dummy = pd.get_dummies(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10952\n",
      "1746\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dmitrii/miniconda3/envs/lr2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dmitrii/miniconda3/envs/lr2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dmitrii/miniconda3/envs/lr2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dmitrii/miniconda3/envs/lr2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dmitrii/miniconda3/envs/lr2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dmitrii/miniconda3/envs/lr2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dmitrii/miniconda3/envs/lr2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dmitrii/miniconda3/envs/lr2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dmitrii/miniconda3/envs/lr2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dmitrii/miniconda3/envs/lr2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dmitrii/miniconda3/envs/lr2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#conv_base = MobileNet(weights='imagenet', include_top=False, input_shape=(128,128,3), pooling='avg')\n",
    "conv_base = MobileNet(weights='imagenet', include_top=False, input_shape=(128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 129, 129, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 64, 64, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 65, 65, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 32, 32, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 32, 32, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 16, 16, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 8, 8, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "=================================================================\n",
      "Total params: 3,228,864\n",
      "Trainable params: 3,206,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 64\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 1024)) #like in conv_pw_13_relu\n",
    "    labels = np.zeros(shape=(sample_count, 10)) # 10 - num of classes\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10952 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = extract_features(train_dir, len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1746 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_features, validation_labels = extract_features(val_dir, len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10952, 4, 4, 1024)\n",
      "(1746, 4, 4, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(validation_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1435.5006879999999\n",
      "228.851856\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(train_features)*1e-6)\n",
    "print(sys.getsizeof(validation_features)*1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_rnn = np.reshape(train_features, (train_features.shape[0], 1, train_features.shape[1]))\n",
    "validation_features_rnn = np.reshape(validation_features, (validation_features.shape[0], 1, validation_features.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_features_rnn.shape)\n",
    "print(validation_features_rnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten them to (samples, 16384):\n",
    "train_features = np.reshape(train_features, (10952, 4 * 4 * 1024))\n",
    "validation_features = np.reshape(validation_features, (1746, 4 * 4 * 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10952, 16384)\n",
      "(1746, 16384)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(validation_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "#model.add(Bidirectional(GRU(256, return_sequences=True, \n",
    "#                             kernel_regularizer=l2(0.01), \n",
    "#                             recurrent_regularizer=l2(0.01), \n",
    "#                             bias_regularizer=l2(0.01)),\n",
    "#                        input_shape=(1, 1024)))\n",
    "#model.add(Bidirectional(GRU(256, return_sequences=False, \n",
    "#                             kernel_regularizer=l2(0.01), \n",
    "#                             recurrent_regularizer=l2(0.01), \n",
    "#                             bias_regularizer=l2(0.01))))\n",
    "#model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "#model.add(Bidirectional(GRU(256, return_sequences=False, \n",
    "#                             kernel_regularizer=l2(0.01), \n",
    "#                             recurrent_regularizer=l2(0.01), \n",
    "#                             bias_regularizer=l2(0.01)),\n",
    "#                        input_shape=(1, 1024)))\n",
    "#model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dmitrii/miniconda3/envs/lr2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=4 * 4 * 1024))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 4,197,130\n",
      "Trainable params: 4,197,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "save_weights = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dmitrii/miniconda3/envs/lr2/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/dmitrii/miniconda3/envs/lr2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dmitrii/miniconda3/envs/lr2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 10952 samples, validate on 1746 samples\n",
      "Epoch 1/10\n",
      "10952/10952 [==============================] - 16s 2ms/step - loss: 3.5571 - acc: 0.3022 - val_loss: 2.2838 - val_acc: 0.0991\n",
      "Epoch 2/10\n",
      "10952/10952 [==============================] - 14s 1ms/step - loss: 1.2579 - acc: 0.5031 - val_loss: 2.3684 - val_acc: 0.1140\n",
      "Epoch 3/10\n",
      "10952/10952 [==============================] - 15s 1ms/step - loss: 1.0089 - acc: 0.5926 - val_loss: 2.7455 - val_acc: 0.1094\n",
      "Epoch 4/10\n",
      "10952/10952 [==============================] - 15s 1ms/step - loss: 0.8169 - acc: 0.6705 - val_loss: 3.1515 - val_acc: 0.1077\n",
      "Epoch 5/10\n",
      "10952/10952 [==============================] - 16s 1ms/step - loss: 0.7015 - acc: 0.7154 - val_loss: 3.4247 - val_acc: 0.1214\n",
      "Epoch 6/10\n",
      "10952/10952 [==============================] - 15s 1ms/step - loss: 0.6428 - acc: 0.7429 - val_loss: 2.9080 - val_acc: 0.1392\n",
      "Epoch 7/10\n",
      "10952/10952 [==============================] - 15s 1ms/step - loss: 0.5752 - acc: 0.7650 - val_loss: 3.5965 - val_acc: 0.1231\n",
      "Epoch 8/10\n",
      "10952/10952 [==============================] - 15s 1ms/step - loss: 0.5568 - acc: 0.7730 - val_loss: 4.6785 - val_acc: 0.1420\n",
      "Epoch 9/10\n",
      "10952/10952 [==============================] - 15s 1ms/step - loss: 0.4830 - acc: 0.7975 - val_loss: 4.2099 - val_acc: 0.1397\n",
      "Epoch 10/10\n",
      "10952/10952 [==============================] - 14s 1ms/step - loss: 0.4592 - acc: 0.8126 - val_loss: 4.4543 - val_acc: 0.1283\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    callbacks=[save_weights],\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weight.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counter = 0\n",
    "#for classi in classes_num:\n",
    "#    for person in tqdm(test_people):\n",
    "#        for word_id in word_ids:\n",
    "#            for f in sorted(glob.glob(os.path.join('MIRACL/'+person+'/words/'+classi+'/'+ word_id, \"*.jpg\"))):\n",
    "#                img = cv2.imread(f, 1)\n",
    "#                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#                rects = detector(gray, 0)\n",
    "#                \n",
    "#                for k, rect in enumerate(rects):\n",
    "#                    x1 = rect.left()\n",
    "#                    y1 = rect.top()\n",
    "#                    x2 = rect.right()\n",
    "#                    y2 = rect.bottom()\n",
    "#                    \n",
    "#                    offset_x = (128-(abs(x1-x2)))/2\n",
    "#                    offset_y = (128-(abs(y1-y2)))/2\n",
    "#                    \n",
    "#                    img = img[int(y1-offset_y):int(y2+offset_y), int(x1-offset_x):int(x2+offset_x)]\n",
    "#                \n",
    "#                counter += 1\n",
    "#                \n",
    "#                cv2.imwrite('data/test/' + classes_dict[classi] + '/' + classi + '_' \n",
    "#                            + person + '_' \n",
    "#                            + word_id + '_' \n",
    "#                            + 'frame' + f[29:-4] + '.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:11<00:00,  5.85s/it]\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.24s/it]\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.41s/it]\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.01s/it]\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.53s/it]\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.81s/it]\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.47s/it]\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.21s/it]\n",
      "100%|██████████| 2/2 [00:14<00:00,  7.12s/it]\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.81s/it]\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('test_MIRACL/*')\n",
    "for file_rem in files:\n",
    "    os.remove(file_rem)\n",
    "\n",
    "counter = 0\n",
    "for classi in classes_num:\n",
    "    for person in tqdm(test_people):\n",
    "        for word_id in word_ids:\n",
    "            for f in sorted(glob.glob(os.path.join('MIRACL/'+person+'/words/'+classi+'/'+ word_id, \"*.jpg\"))):\n",
    "                img = cv2.imread(f, 1)\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                rects = detector(gray, 0)\n",
    "                \n",
    "                for k, rect in enumerate(rects):\n",
    "                    x1 = rect.left()\n",
    "                    y1 = rect.top()\n",
    "                    x2 = rect.right()\n",
    "                    y2 = rect.bottom()\n",
    "                    \n",
    "                    offset_x = (128-(abs(x1-x2)))/2\n",
    "                    offset_y = (128-(abs(y1-y2)))/2\n",
    "                    \n",
    "                    img = img[int(y1-offset_y):int(y2+offset_y), int(x1-offset_x):int(x2+offset_x)]\n",
    "                \n",
    "                counter += 1\n",
    "                \n",
    "                cv2.imwrite('test_MIRACL/' + classi + '_' \n",
    "                            + person + '_' \n",
    "                            + word_id + '_' \n",
    "                            + 'frame' + f[29:-4] + '.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1639/1639 [00:00<00:00, 1668.42it/s]\n"
     ]
    }
   ],
   "source": [
    "images = glob.glob(\"test_MIRACL/*.jpg\")\n",
    "test_image = []\n",
    "test_class = []\n",
    "for i in tqdm(range(len(images))):\n",
    "    test_image.append(sorted(images)[i].split('/')[1])\n",
    "    test_class.append(sorted(images)[i].split('/')[1][:2])\n",
    "\n",
    "\n",
    "test_data = pd.DataFrame()\n",
    "test_data['image'] = test_image\n",
    "test_data['class'] = test_class\n",
    "test_images = test_data['image']\n",
    "\n",
    "test_data.to_csv('test_new.csv',header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01_F11_01_frame001.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_F11_01_frame002.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01_F11_01_frame003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01_F11_01_frame004.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01_F11_01_frame005.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    image  class\n",
       "0  01_F11_01_frame001.jpg      1\n",
       "1  01_F11_01_frame002.jpg      1\n",
       "2  01_F11_01_frame003.jpg      1\n",
       "3  01_F11_01_frame004.jpg      1\n",
       "4  01_F11_01_frame005.jpg      1"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_new.csv')\n",
    "y_test = test['class']\n",
    "y_test = pd.get_dummies(y_test)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    01_F11_01\n",
       "1    01_F11_02\n",
       "2    01_F11_03\n",
       "3    01_F11_04\n",
       "4    01_F11_05\n",
       "Name: dummy, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_names = sorted(list(set([test_images[i].split('.')[0][0:9] for i in range(len(test_images))])))\n",
    "test_videos = pd.DataFrame(video_names)\n",
    "\n",
    "test_videos.columns = ['dummy']\n",
    "test_videos = test_videos['dummy']\n",
    "\n",
    "print(test_videos.shape[0])\n",
    "test_videos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1634    10_M08_10_frame003.jpg\n",
       "1635    10_M08_10_frame004.jpg\n",
       "1636    10_M08_10_frame005.jpg\n",
       "1637    10_M08_10_frame006.jpg\n",
       "1638    10_M08_10_frame007.jpg\n",
       "Name: image, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_images.shape[0])\n",
    "test_images.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:29<00:00,  2.24it/s]\n"
     ]
    }
   ],
   "source": [
    "predict = []\n",
    "actual = []\n",
    "\n",
    "for video_id in tqdm(range(test_videos.shape[0])):\n",
    "    videoFile = test_videos[video_id]\n",
    "    \n",
    "    files = glob.glob('temp/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    \n",
    "    for frame_id in range(test_images.shape[0]):\n",
    "        frame = test_images[frame_id]\n",
    "        if test_images[frame_id].split('.')[0][0:9] == videoFile:\n",
    "            img = shutil.copyfile('test_MIRACL/'+test_images[frame_id], 'temp/'+test_images[frame_id]) \n",
    "    \n",
    "    images = glob.glob(\"temp/*.jpg\")\n",
    "    \n",
    "    prediction_images = []\n",
    "    for i in range(len(images)):\n",
    "        img = image.load_img(images[i], target_size=(128,128,3))\n",
    "        img = image.img_to_array(img)\n",
    "        img = keras.applications.mobilenet.preprocess_input(img)\n",
    "        \n",
    "        prediction_images.append(img)\n",
    "        \n",
    "    prediction_images = np.array(prediction_images)\n",
    "    \n",
    "    prediction_images = conv_base.predict(prediction_images)\n",
    "    \n",
    "    prediction_images = prediction_images.reshape(prediction_images.shape[0], 4 * 4 * 1024)\n",
    "    \n",
    "    prediction = model.predict_classes(prediction_images)\n",
    "    predict.append(y_test.columns.values[s.mode(prediction)[0][0]])\n",
    "    \n",
    "    actual.append(int(videoFile.split('_')[0].lstrip('0')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.5"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predict, actual)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
