{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python361064bitlr236venv3bda875d1eee442badac76530344396b",
   "display_name": "Python 3.6.10 64-bit ('lr2_3.6': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dlib\n",
    "import glob\n",
    "import random as rn\n",
    "import math\n",
    "import csv\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = 'true'\n",
    "rn.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "print(tf.config.experimental.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_video_datagen import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator()\n",
    "\n",
    "train_data = datagen.flow_from_directory('data/train', \n",
    "                                         target_size=(70, 140), \n",
    "                                         batch_size=5, \n",
    "                                         frames_per_step=13, \n",
    "                                         shuffle=False, \n",
    "                                         color_mode='rgb')\n",
    "\n",
    "val_data = datagen.flow_from_directory('data/validation', \n",
    "                                       target_size=(70, 140), \n",
    "                                       batch_size=5, \n",
    "                                       frames_per_step=13, \n",
    "                                       shuffle=False, \n",
    "                                       color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_data.next()\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(math.ceil(13559/(5*13)))\n",
    "print(math.ceil((2366/(5*13))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import ZeroPadding3D, Conv3D, BatchNormalization, Activation, MaxPooling3D, TimeDistributed, Flatten, Bidirectional, GRU, Dense\n",
    "\n",
    "def build_model():\n",
    "    model_small = keras.models.Sequential()\n",
    "\n",
    "    model_small.add(ZeroPadding3D(padding=(1, 2, 2), input_shape=(13, 70, 140, 3)))\n",
    "    model_small.add(Conv3D(32, (3, 5, 5), strides=(1, 2, 2), use_bias=False))\n",
    "    model_small.add(BatchNormalization(momentum=0.99))\n",
    "    model_small.add(Activation('relu'))\n",
    "    model_small.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "\n",
    "    model_small.add(ZeroPadding3D(padding=(1, 2, 2)))\n",
    "    model_small.add(Conv3D(64, (3, 5, 5), strides=(1, 1, 1), use_bias=False))\n",
    "    model_small.add(BatchNormalization(momentum=0.99))\n",
    "    model_small.add(Activation('relu'))\n",
    "    model_small.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "\n",
    "    model_small.add(ZeroPadding3D(padding=(1, 1, 1)))\n",
    "    model_small.add(Conv3D(96, (3, 3, 3), strides=(1, 2, 2), use_bias=False))\n",
    "    model_small.add(BatchNormalization(momentum=0.99))\n",
    "    model_small.add(Activation('relu'))\n",
    "    model_small.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "\n",
    "    model_small.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    model_small.add(Bidirectional(GRU(65, return_sequences=False, activation='tanh')))\n",
    "\n",
    "    model_small.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    return model_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_record():\n",
    "    record = {}\n",
    "    record['loss'] = []\n",
    "    record['accuracy'] = []\n",
    "    record['val_loss'] = []\n",
    "    record['val_accuracy'] = []\n",
    "\n",
    "    record['loss'] += history.history['loss']\n",
    "    record['accuracy'] += history.history['accuracy']\n",
    "    record['val_loss'] += history.history['val_loss']\n",
    "    record['val_accuracy'] += history.history['val_accuracy']\n",
    "\n",
    "    return record\n",
    "\n",
    "def play_sound(duration = 0.1, freq = 310):\n",
    "    for time in range(10):\n",
    "        os.system('play -nq -t alsa synth {} sine {}'.format(duration, freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "momentum = 0.95\n",
    "index = 2\n",
    "\n",
    "model = build_model()\n",
    "sgd = keras.optimizers.SGD(lr=lr, momentum=momentum, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(\"\\nRun #%d. Learning rate = %f, Momentum = %f\" % (index, K.eval(model.optimizer.lr), K.eval(model.optimizer.momentum)))\n",
    "csv_file = \"%d_record_%f_%f.csv\" % (index, K.eval(model.optimizer.lr), K.eval(model.optimizer.momentum))\n",
    "\n",
    "# print(model.layers[6].kernel[0][0][0][0][:4])\n",
    "history = model.fit_generator(train_data, epochs=100, steps_per_epoch=209, \n",
    "                            validation_data=val_data, validation_steps=37, shuffle=False)\n",
    "# print(model.layers[6].kernel[0][0][0][0][:4])\n",
    "\n",
    "record = set_record()\n",
    "with open(csv_file, 'w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(record.keys())\n",
    "    for i in range(len(record['loss'])):\n",
    "        a = []\n",
    "        for idx in range(len(record)):\n",
    "            a.append(list(record.values())[idx][i])\n",
    "        w.writerow(a)\n",
    "os.remove(csv_file)\n",
    "\n",
    "del model\n",
    "del history\n",
    "del sgd\n",
    "del record\n",
    "for i in range(3): gc.collect()\n",
    "\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "index += 1\n",
    "\n",
    "play_sound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}